\chapter{Discussion}

\section{Waveform Morphology}
The results we got for the waveform morphology did not speak entirely with the results that Weder et al. \citeyearpar{Weder2018} reported. In most of the cases, larger sound pressure levels did result in greater positive changes in oxygenated hemoglobin concentration, or in other words, greater negative changes in deoxygenated hemoglobin concentration. However, the results were not consistent between participants. The separation between different sound pressure levels could not be clearly seen. Apart from the results with the loudest auditory stimuli, responses from other quieter auditory stimuli were rather indistinguishable. Moreover, regarding the type of responses we measured from different regions of the left brain hemisphere, phasic responses could be observed from the channels over the supramarginal superior temporal gyrus from most of the participants. However, only from some of the pariticipants, channels over Broca's area could show a broad tonic pattern as Weder et al. \citeyearpar{Weder2018} described.

\section {Regional Analysis}
In comparison to the research from Weder et al. \citeyearpar{Weder2018}, we chose a different approach to define our region of interest. Instead of first looking at the results and grouping different regions according to similar waveforms, we were more interested to know how the responses from the auditory cortex would be compared with other regions of the measured left brain hemisphere, so we grouped the three channels over the caudal superior temporal gyrus as one region (ROI 2), and the rest of the channels as another region (ROI 1).

The auditory cortex ~\ref{fig:CerebralCortex} was our interest in this study. It is around the caudal superior temporal gyrus. We compared the hemoglobin response from the three channels over the auditory cortex with all the other channels lying on the rest of the measured left brain hemisphere. The waveform morphology of the auditory cortex is very similar to the counterparts of the rest of the measured parts. In other words, the dynamic hemoglobin response of the auditory cortex represents that of the entire left brain hemisphere fairly well.

\begin{figure}[H]
  \centering
     \copyrightbox[b]{\includegraphics[scale=.3]{bilder/cerebral_cortex.jpg}}%
           {Source: \url{https://human-memory.net/sensory-cortex/}}
  \caption{Motor and sensory regions of the cerebral cortex}
  \label{fig:CerebralCortex}
\end{figure}

\section{Device Limitation and fNIRS Testing Conditions}

There were several factors that potentially caused the results from this project to vary from that Weder et al. \citeyearpar{Weder2018} reported. First, we used the device Brite23. It is also a continuous-wave fNIRS device. The sources emitted light of slightly different wavelengths, which are 757 nm and 843 nm, whereas Weder et al. \citeyearpar{Weder2018} used the device (NIRScout, NIRX, Germany) which sources emitted light of wavelengths 760 nm and 850 nm. Additionally, as for the fNIRS testing procedure, we could have also improved on several things. To begin with, a darker sound-attenuating booth would be more suitable. In our setup, the testing was also performed in a sound-attenuating cabin, but with normal light conditions. Still, if the lighting was dimmer, there could be less noise in the hemoglobin response from visual stimulation. In addition, it would make sense to stabilize the participant's neck with a neck cushion. Not only would it be more comfortable for the participants during the measurement. Motion artifacts could also be reduced. Moreover, by including breaks in between, participants might be able to maintain better attention.

Also, from our measurements, data from female participants with long hair had worse data quality. In our configuration, since we were only measuring the left brain hemisphere. First asking the participant to put the hair to the right side made it easier to put the cap on. Sometimes when the participants had thick long hair, trying to put the hair aside can be a futile attempt, but it was easier when they first put the hair to the other side. Last but not least, we would be curious to know how the hemoglobin responses from more people are like. If possible, more participants should be measured so the results from the project can be more credible. For example, participants of different ages and every gender and race would be desirable for this hearing research. Besides, other than only measuring normal-hearing people, it would also be of great interest to measure some cochlear implant users and compare the results together.

\section {Data Processing}
Our measured data was processed with a modified approach. In the research from Weder et al. \citeyearpar{Weder2018}, data pre-processing and analysis was executed in MATLAB and SPSS (version 24, IBM Corp., USA). They combined custom-made MATLAB scripts with Homer2 \citep{Huppert:09} functions. On the other hand, the newer Homer3 \citep{Huppert:09} with our MATLAB script in this study. Judging from the varying individual results, group analysis or statistical analysis will not be applicable in this case. Hence, the software program for statistical analysis, SPSS, was not used in this project. Furthermore, the differential path length factor (DPF) for each participant was calculated from their age. The resultant HbO and HbR concentration was estimated with the correction factor, whereas Weder et al. \citeyearpar{Weder2018} did not mention how they chose or calculated the DPF values.

\section{Loudness Perception}
In this project, results from individuals varied much. Although in hearing research, the response from normal-hearing participants are often similar and reproducible, it is also well-known that, even among normal-hearing listeners,
considerable differences still exist in loudness perceptions \citep{Brand2001}. More recent research \citep{Weder2020} was conducted in detail, and showed that brain activation in response to different stimulus intensities is more reliant upon individual loudness sensation than the physical stimulus properties. Therefore, the authors suggested that loudness
estimates should be examined when interpreting results, especially when it comes to measurements using different auditory stimulus intensities. Different loudness perception can explain the varying results from individual participants.

\section{Intelligibility of the Auditory Stimuli}
ICRA noises were chosen as the stimuli in this study because it is believed to be able to activate broad cortical auditory areas. However, some other studies were able to detect differences in cortical responses to the speech of different intelligibility. Pollonini et al. \citeyearpar{Pollonini2013} found that normal speech evoked stronger respsonses within the auditory cortex than distorted speech did, and environmental sounds produced the least cortical activation. ICRA noises are amplitude-modulated noises, are completely unintelligible, and thus, belong to the distorted-speech category. Although ICRA noises may be able to activate broader cortical auditory areas compared to a simple static stimulus, normal speech can perhaps produce even stronger responses within the auditory cortex, according to Pollonini et al. \citeyearpar{Pollonini2013}. In addition, by providing intelligible normal speech as a stimulus rather than unintelligible noise, the measurement process can be less boring for the participants. They can then be more compliant and thus maintain better attention to actively listen to the soundtracks.

\section{Language Processing in Human Brains}
One primary goal of fNIRS research is to improve a patient's ability to discriminate speech. In many studies, topics associated with hearing and language processing were investigated. However, language perception and processing in the human brain do not have to be involved with auditory stimuli. Visual-only speech can also activate language processing in the human brain. Shader et al. \citeyearpar{Shader2021} used both auditory-only and visual-only connected speech as stimuli in their research. Their results suggested that Heschl's gyrus (see Figure ~\ref{fig:gyrus}) may be the most advantageous location for identifying hemodynamic responses to complex auditory speech signals using fNIRS, for measuring responses to visual speech with fNIRS, regions corresponding to the facial processing pathway in the occipital lobe can be more advantageous.

\section{Laterality of Brain Activation}
In the present study, the fNIRS optodes were all placed on the left brain hemisphere, since according to Frost et al. \citeyearpar{Frost1999-vs}, language processing is strongly left lateralized. Nonetheless, from other papers, different results were observed and did not speak entirely with the conclusion from Frost et al. \citeyearpar{Frost1999-vs}. For example, the data from Pollonini et al. \citeyearpar{Pollonini2013} is more responsive to changes in activation within the right hemisphere. Belin et al. \citeyearpar{Belin2000} showed that the voice-selective regions can be found bilaterally along the upper bank of \acrshort{sts}. Shader et al. \citep{Shader2021} also measured relatively symmetrical patterns across both hemispheres. Hence, if it is more advantageous to measure the left hemisphere for cortical response to audiometric stimuli with fNIRS remains till this point a question to be answered.

\section{Depth and Location of Cortical Response} % to Complex Auditory Speech Signals 
The depth of cortical response to complex auditory speech signals can also greatly affect the fNIRS measurements. Strangman et al. \citeyearpar{Strangman2013} demonstrated that sensitivity in depth decreases exponentially and diminishing returns appear to begin around 40 to 50 mm source-detector separations.

The left inferior frontal gyrus (see Figure ~\ref{fig:gyrus}), or more specifically Broca's area (see Figure ~\ref{fig:CerebralCortex}) is implicated in higher-level linguistic processing \citep{Belin2000}. While in some studies \citep{Wijayasir2017} \citep{Zhou2018}, significant cortical activity in response to auditory speech signals in this region can be detected, it was not always the case \citep{Musthtaq2019}. The studies that observed significant activation in the frontal region used fMRI or a combination of fMRI and fNIRS. It is possible that speech-evoked activity in the inferior frontal gyrus is isolated to the deeper cortical areas, so it's less likely to be detected with \acrshort{fnirs}. Different neuroimaging methods can also explain why some studies \citep{Frost1999-vs} reported language processing to be left-lateralized whereas in other studies \citep{Shader2021}, opposite results were observed. It is possible that speech-evoked activities are related to the deeper cortical areas in the left hemisphere while the stimuli evoked responses in more superficial areas of the right cortex, making them more easily detected by fNIRS.

\begin{figure}[h]
  \centering
     \copyrightbox[b]{\includegraphics[scale=.5]{bilder/gyrus.jpeg}}%
           {Source: \url{https://www.tabers.com/tabersonline/view/Tabers-Dictionary/734639/all/gyrus}}
  \caption{Gyrus}
  \label{fig:gyrus}
\end{figure}


\section{HbR and HbO Data}
Most fNIRS studies only present HbO data \citep{Ferrari2012}, since it has a lower noise level, and thus more obvious responses can be observed. However, with our system, no significant difference was found regarding the HbO and HbR noise levels for most of the participants. Only some channels were measured with higher noise levels for the HbR data collected from participant 6. Unlike what Weder et al. \citeyearpar{Weder2018} presented in their paper, we were surprised to be able to measure comparably the same magnitude of HbO and HbR responses.


